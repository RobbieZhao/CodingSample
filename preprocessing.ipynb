{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'D:/DLcompetition/data/train'\n",
    "test_path = 'D:/DLcompetition/data/test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model For Scene A\n",
    "\n",
    "## Four tables in total：\n",
    "\n",
    "* train_behavior_A.csv: consumer table\n",
    "  * 21245 ccx_id, each ccx_id corresponds to a entry (a customer)\n",
    "  * 2270 labels: var1-var2270\n",
    "  * var19 is time\n",
    "* train_consumer_A.csv: behavior table\n",
    "  * 268453 entries, each ccx_id corresponds to multiple entries (multiple behaviors)\n",
    "  * 14 labels: V_1-V_14\n",
    "  * V_7 and V_11 are time\n",
    "* train_ccx_A.csv: record history\n",
    "  * 53983 entries, each ccx_id corresponds to multiple entries（multiple records）\n",
    "  * 6 labels: var_01-var_06\n",
    "* train_target_A.csv: labels\n",
    "  * 21245 ccx_id, each ccx_id corresponds to one target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing for Scene A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ccx_A history record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ccx_A = pd.read_csv(train_path + '/' + 'train_ccx_A.csv', index_col=0, parse_dates = [\"var_06\"])\n",
    "test_ccx_A = pd.read_csv(test_path + '/' + 'test_ccx_A.csv', index_col=0, parse_dates = [\"var_06\"])\n",
    "all_ccx = pd.concat([train_ccx_A, test_ccx_A])\n",
    "# print(all_ccx.isnull().sum()) no N/A in ccx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle strings.\n",
    "# Create columns for each different string value. The values under the columns are number of appearances for each id.\n",
    "def Clean_history(data, column):\n",
    "    # make a copy to facilitate counting\n",
    "    data = data.copy()\n",
    "    data['zeros'] = np.zeros(len(data))\n",
    "    group = data.reset_index()[['zeros', 'ccx_id', column]].groupby(['ccx_id', column])\n",
    "    data = group.count().unstack([column])['zeros'].fillna(0)\n",
    "    data.columns = [column + '_' + data.columns[i] + '_count' for i in range(len(data.columns))]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ccx_master = pd.concat([Clean_history(all_ccx, column) for column in all_ccx.columns[:5]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For the date column, we extra four different columns\n",
    "# 1. The time range under an id\n",
    "# 2. How many different dates under one id\n",
    "# 3. Frequecy: column 2 divided by column 1\n",
    "# 4. Average number of records per id\n",
    "def Date_transform(data, column):\n",
    "    group = (data[column] - min(data[column])).groupby('ccx_id')\n",
    "    different_days_num = data.reset_index().groupby([\"ccx_id\", column]).first().reset_index()[['ccx_id', column]].groupby('ccx_id').count()\n",
    "    date_length = group.max().astype('timedelta64[D]').astype(int) + 1\n",
    "    date_info = pd.concat([date_length, different_days_num, different_days_num / pd.DataFrame(date_length), pd.DataFrame(group.count()) / different_days_num], axis=1)\n",
    "    date_info.columns = [column + '_' + item for item in ['daylength', 'numdays', 'frequencies', 'numperday']]\n",
    "    return date_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccx_master = ccx_master.join(Date_transform(all_ccx, 'var_06'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. consumer_A consumer information data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_consumer_A = pd.read_csv(train_path + '/' + 'train_consumer_A.csv', index_col=0)\n",
    "test_consumer_A = pd.read_csv(test_path + '/' + 'test_consumer_A.csv', index_col=0)\n",
    "all_consumer = pd.concat([train_consumer_A, test_consumer_A])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Replace the outlier with nan\n",
    "index = all_consumer[all_consumer['V_12'] == max(all_consumer['V_12'])].index[0]\n",
    "all_consumer['V_12'][index] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For the mode of a column which is of type string for each id\n",
    "def String_mode(data, column):\n",
    "    counts = data[[column]].reset_index().reset_index().groupby(['ccx_id', column]).count()\n",
    "    mode = counts.reset_index().set_index(['ccx_id', 'index']).sort_index(ascending=False).groupby('ccx_id').first()\n",
    "    mode = mode.rename(columns={\"index\": column})\n",
    "    return mode\n",
    "\n",
    "# numeric column. replace null with median\n",
    "medians = pd.concat([all_consumer[['V_' + num]].groupby('ccx_id').median() for num in ['12', '13']], axis=1)\n",
    "all_consumer = all_consumer.fillna(medians.loc[all_consumer.index].fillna(medians.median()))\n",
    "# string type column , replace null with mode\n",
    "modes = pd.concat([String_mode(all_consumer, 'V_' + num) for num in ['8', '14']], axis=1)\n",
    "all_consumer = all_consumer.fillna(modes.loc[all_consumer.index].fillna(modes.mode().iloc[0]))\n",
    "# How many records per id.\n",
    "consumer_count = all_consumer['V_1'].reset_index().groupby('ccx_id').count().rename(columns={\"V_1\": \"consumer_count\"})\n",
    "# 对V_1, V_2, V_3三列进行组合，数出每个id有多少个城市\n",
    "# For V_1, V_2, V_3, count the number of cities for each id.\n",
    "places_count = all_consumer[['V_1', 'V_2', 'V_3']].reset_index().reset_index().groupby(['ccx_id', 'V_1', 'V_2', 'V_3']).count().groupby('ccx_id').count().rename(columns={\"index\": \"places_count\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For numeric column, calculate min, max, median, and average of each id\n",
    "def Num_transform(data, column):\n",
    "    group = all_consumer[['V_4']].groupby('ccx_id')\n",
    "    transformed = pd.concat([group.min(), group.median(), group.max(), group.mean(), group.std().fillna(0)], axis=1)\n",
    "    transformed.columns = [column + '_' + item for item in ['min', 'median', 'max', 'mean', 'std']]\n",
    "    return transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transformed_numbers = pd.concat([Num_transform(all_consumer, 'V_' + str(i)) for i in [4, 5, 6, 9, 10, 12, 13]], axis=1)\n",
    "transformed_strings = pd.concat([Clean_history(all_consumer, 'V_' + num) for num in ['8', '14']], axis=1)\n",
    "# For V_7, count the number of dates per id.\n",
    "distinct_timecount = all_consumer[['V_7']].reset_index().reset_index().groupby(['ccx_id', 'V_7']).count().groupby('ccx_id').count().rename(columns = {\"index\": \"V_7\"})\n",
    "# For V_11，count the number of rows that has value \"0000-00-00 00:00:00\"\n",
    "zerotime_count = all_consumer[all_consumer['V_11'] == '0000-00-00 00:00:00'][['V_11']].groupby('ccx_id').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_master = pd.concat([consumer_count, places_count, transformed_numbers, transformed_strings, \n",
    "                             distinct_timecount, zerotime_count], axis=1).fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## 3. behavior_A Consumer table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2728: DtypeWarning: Columns (14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "train_behavior_A = pd.read_csv(train_path + '/' + 'train_behavior_A.csv', index_col=0)\n",
    "test_behavior_A = pd.read_csv(test_path + '/' + 'test_behavior_A.csv', index_col=0)\n",
    "all_behavior = pd.concat([train_behavior_A, test_behavior_A])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fill out the null values, and calculate the time range between var17 and var16\n",
    "all_behavior['var10'] = all_behavior['var10'].fillna(0)\n",
    "all_behavior['yearlength'] = all_behavior['var17'] - all_behavior['var16']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.preprocessing as prep\n",
    "\n",
    "def Cat_to_bin(data, a = 0.01):\n",
    "    '''Transfrom a categorical column to onehotencoding'''\n",
    "    tmp = pd.value_counts(data)/data.shape[0]\n",
    "    cat = list(tmp.index[tmp > a])\n",
    "    enc = prep.OneHotEncoder(n_values = len(cat)+1, sparse = False)\n",
    "    xbin = enc.fit_transform(np.transpose(\n",
    "            [data.astype(\"category\").cat.set_categories(cat).cat.rename_categories(1+np.arange(len(cat))).astype(\"float\").fillna(0).values]))[:,1:]     \n",
    "    dabin = pd.DataFrame(xbin, columns = [\"{}_{}\".format(data.name, x) for x in cat], index = data.index)\n",
    "    if(tmp[tmp <= a].sum() > a):\n",
    "        dabin = pd.concat([dabin, pd.DataFrame({\"{}_Others\".format(data.name):data.notnull()-dabin.sum(axis = 1)})], axis = 1)\n",
    "    if(dabin.shape[1] == 2):\n",
    "        dabin = pd.DataFrame({data.name: xbin[:,0]}, index = data.index)\n",
    "    return(dabin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_bin = pd.concat([Cat_to_bin(all_behavior['var' + str(i)]) for i in [3, 4, 5, 6, 11, 12, 13, 14, 15, 18, 19]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "behavior_master = pd.concat([all_behavior.drop(['var' + str(i) for i in [3, 4, 5, 6, 11, 12, 13, 14, 15, 18, 19]], axis=1), \n",
    "                             data_bin], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "master = pd.concat([behavior_master, consumer_master, ccx_master], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Value_counts(data, nhead = 5):\n",
    "    tmp = pd.value_counts(data).reset_index().rename_axis({\"index\": data.name}, axis = 1)\n",
    "    value = pd.DataFrame(['value {}'.format(x+1) for x in range(nhead)], index = np.arange(nhead)).join(tmp.iloc[:,0], how = \"left\").set_index(0).T\n",
    "    freq = pd.DataFrame(['freq {}'.format(x+1) for x in range(nhead)], index = np.arange(nhead)).join(tmp.iloc[:,1], how = \"left\").set_index(0).T\n",
    "    nnull = data.isnull().sum()\n",
    "    freqother = pd.DataFrame({data.name: [data.shape[0]-nnull-np.nansum(freq.values), nnull]}, index = [\"freq others\", \"freq NA\"]).T\n",
    "    counts = pd.concat([value, freq, freqother], axis = 1)\n",
    "    if 'level_0' in counts.index:\n",
    "        print(data.name)\n",
    "    return(counts)\n",
    "\n",
    "tmp = pd.concat(map(lambda i: Value_counts(master.loc[:,i]), master.columns))\n",
    "# For each column, if the number of null values and the number of modes\n",
    "# account for over 99.9% of this column, then drop it \n",
    "master = master.loc[:, (tmp[\"freq 1\"] + tmp[\"freq NA\"])/master.shape[0] < 0.999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# drop columns that has correlation over 0.99\n",
    "master = master.drop(master.columns[np.any(np.abs(np.tril(np.corrcoef(master.rank(pct = True).fillna(0.5).values, rowvar = 0), -1)) > 0.99, axis = 0)], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in master.columns:\n",
    "    if column in consumer_master or column in ccx_master:\n",
    "        master[column] = master[column].fillna(0)\n",
    "\n",
    "master = master.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target_A = pd.read_csv(train_path + '/' + 'train_target_A.csv', index_col=0)\n",
    "master = master.join(train_target_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "master.to_csv('master.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
